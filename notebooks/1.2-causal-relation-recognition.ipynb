{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d1484c-1506-4e2d-9e5f-25725be7bb6d",
   "metadata": {},
   "source": [
    "# Causal relation recognition. \n",
    "Find phrases of relations in text: either concepts, explanations or not present in a relation\n",
    "\n",
    "**NB: this notebooks contains snippets from the original notebook for insipration, but it doesn't work yet!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1a933-c879-41e7-b7cf-6f66cae0fdf6",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "\n",
    "This notebook expects three files in a subdirectory `csv`: `Map_Contents-20200726.csv`, `Speech_Contents-20210520.txt` and `Speeches-20210520.txt`. It will look for files with the speeches in the subdirectory `txt`. The names of the speech files are expected to start with the date followed by a space and the suname of the speaker (currently restricted to one word, see function `get_speech_id`).\n",
    "\n",
    "If you are just interested in learning what the code is doing, you can skip all code blocks with the commands `import` (load libraries), `assert` (perform tests) and `def` (define functions), and examine the other code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b790b5ee-1747-4b65-a033-516621cd246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.data.make_dataset import read_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4ce3ca-f0e7-4fba-9993-603d56ede46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(\"csv\"), 'The directory \"csv\" does not exist!'\n",
    "assert os.path.isdir(\"txt\"), 'The directory \"txt\" does not exist!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f413636-f400-4e0e-a34f-1b0a41c2ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_contents = read_data_file(\"csv/Map_Contents-20200726.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979f6245-1dfb-4119-ba80-525acbcec0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_contents = read_data_file(\"csv/Speech_Contents-20210520.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59386793-927f-4214-8375-71b0a8ae00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = read_data_file(\"csv/Speeches-20210520.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d21ca-e3bf-41d9-a95e-704492c5cca1",
   "metadata": {},
   "source": [
    "## 1.1. Data encoding for plan step 2\n",
    "\n",
    "contribute E\\\n",
    "to E\\\n",
    "increase E\\\n",
    "confidence C\\\n",
    "between C\\\n",
    "the C\\\n",
    "banks C\\\n",
    "the X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e3338c-0d9f-469c-ada4-068f826f57c2",
   "metadata": {},
   "source": [
    "## 4. Task 2: Find relevant phrases in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fe352-365e-456b-bd70-37e187c27e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695196e-a515-4903-8235-85e578cc6304",
   "metadata": {},
   "source": [
    "### 4.1 Testing the pretrained Named Entity Recognition (NER) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a58c0b-bd90-4bd2-8680-5d00def0abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2e944-0e69-46cc-b802-5d0ea8859a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paragraph_list[0])\n",
    "classifier(paragraph_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ac976-c831-437e-95c4-3be3de29dba2",
   "metadata": {},
   "source": [
    "### 4.2 Training a phrase recognition model\n",
    "\n",
    "Source: https://huggingface.co/transformers/task_summary.html#named-entity-recognition\n",
    "\n",
    "This does not change the behaviour of the system. Perhaps we need to start from https://github.com/huggingface/transformers/blob/master/examples/pytorch/token-classification/run_ner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716c063-d8d3-418a-8400-b07a2a274296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "label_list = [\n",
    "    \"O\",       # Outside of a phrase\n",
    "    \"I-CON\"    # Concept\n",
    "    \"I-EXP\"    # Explanation\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ba9d3-4d23-4ae8-a7b0-209b9cb427aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = paragraph_list[0]\n",
    "\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "outputs = model(inputs).logits\n",
    "predictions = torch.argmax(outputs, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c0fd5-c4c7-40da-ac7d-3de9611fd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484edfa-4157-4968-ab19-a523321df343",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e9099-ff56-4640-aac8-d3dd903c8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
