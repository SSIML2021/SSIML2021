{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning model performance often improves with dataset size for predictive modeling.\n",
    "\n",
    "This depends on the specific datasets and on the choice of model, although it often means that using more data can result in better performance and that discoveries made using smaller datasets to estimate model performance often scale to using larger datasets.\n",
    "\n",
    "The problem is the relationship is unknown for a given dataset and model, and may not exist for some datasets and models. Additionally, if such a relationship does exist, there may be a point or points of diminishing returns where adding more data may not improve model performance or where datasets are too small to effectively capture the capability of a model at a larger scale.\n",
    "\n",
    "These issues can be addressed by performing a sensitivity analysis to quantify the relationship between dataset size and model performance. Once calculated, we can interpret the results of the analysis and make decisions about how much data is enough, and how small a dataset may be to effectively estimate performance on larger datasets.\n",
    "\n",
    "The method of this Notebook is based on this tutorial: https://machinelearningmastery.com/sensitivity-analysis-of-dataset-size-vs-model-performance/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Preparation of Bert Classification method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle,resample\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from src.data.make_dataset import read_data_file,make_dataset\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import tqdm\n",
    "import warnings\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,get_linear_schedule_with_warmup,AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "\n",
    "#set random seed to keep consistency between different experiments\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "if str(device) == 'cuda':\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "else:\n",
    "    torch.manual_seed(seed_val)\n",
    "    \n",
    "assert os.path.isdir(\"csv\"), 'The directory \"csv\" does not exist!'\n",
    "assert os.path.isdir(\"txt\"), 'The directory \"txt\" does not exist!'\n",
    "map_contents = read_data_file(\"csv/Map_Contents-20200726.csv\")\n",
    "speech_contents = read_data_file(\"csv/Speech_Contents-20210520.txt\")\n",
    "speeches = read_data_file(\"csv/Speeches-20210520.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mwarning: mismatch meta data (10) vs file (7) for file 1998-12-14 Schroeder ann.txt\u001b[0m\n",
      "skipping file in language fr: 2009-12-01 Sarkozy Elysee (Economy) ann fr.txt\n",
      "skipping file in language fr: 2009-12-14 Sarkozy Elysee (Economy) ann fr.txt\n",
      "\u001b[31mwarning: mismatch meta data (2) vs file (1) for file 2010-03-29 Brown sfm2020 ann.txt\u001b[0m\n",
      "skipping file in language fr: 2010-04-20 Barroso European Commission ann fr.txt\n",
      "skipping file in language fr: 2011-01-13 Sarkozy gb ann.txt\n",
      "skipping file in language nl: 2011-04-06 Rutte FD evenement ann NL.txt\n",
      "\u001b[31mwarning: mismatch meta data (14) vs file (12) for file 2011-05-20 Weidmann Deutsche Bundesbank_01 ANN.txt\u001b[0m\n",
      "skipping file in language nl: 2011-09-27 Rutte Rijksoverheid ann.txt\n",
      "skipping file in language nl: 2011-10-28 Knot dnb_01 ANN NL.txt\n",
      "\u001b[31mwarning: mismatch meta data (4) vs file (3) for file 2011-11-10 Orban London ann.txt\u001b[0m\n",
      "\u001b[31mwarning: mismatch meta data (4) vs file (3) for file 2011-11-12 Rutte Trilateral Commission - code ann.txt\u001b[0m\n",
      "skipping file in language de: 2012-01-06 Rutte CSU klausurtagung ann G.txt\n",
      "\u001b[31mwarning: unknown paragraph id nan for document 208; file name: 2012-02-24 Weidmann Deutsche Bundesbank ann.txt\u001b[0m\n",
      "\u001b[31mwarning: mismatch meta data (24) vs file (22) for file 2012-07-11 Rajoy La Moncloa ann.txt\u001b[0m\n",
      "\u001b[31mwarning: mismatch meta data (11) vs file (10) for file 2012-07-17 Linde Banco de Espana_01 ann.txt\u001b[0m\n",
      "skipping file in language unk: 2012-07-26 Barroso European Commission.txt\n",
      "skipping file in language fr: 2012-08-30 Hollande SFM2020 ann fr.txt\n",
      "\u001b[31mwarning: unknown paragraph id nan for document 335; file name: 2012-10-17 Thorning Schmidt Statsministeriet ann.txt\u001b[0m\n",
      "\u001b[31mwarning: mismatch meta data (21) vs file (20) for file 2012-10-17 Thorning Schmidt Statsministeriet ann.txt\u001b[0m\n",
      "\u001b[31mwarning: mismatch meta data (7) vs file (6) for file 2012-12-07 Simor Bis.org ann.txt\u001b[0m\n",
      "skipping file in language fr: 2013-02-19 Hollande SFM2020 ann fr.txt\n",
      "\u001b[31mwarning: mismatch meta data (19) vs file (18) for file 2013-02-26 Rohde Danmarks Nationalbank ann.txt\u001b[0m\n",
      "skipping file in language fr: 2013-04-17 Hollande SFM2020 ann fr.txt\n",
      "\u001b[31mwarning: mismatch meta data (14) vs file (13) for file 2013-05-31 Linde Banco de Espana_01 ann.txt\u001b[0m\n",
      "\u001b[31mwarning: mismatch meta data (22) vs file (19) for file 2013-10-08 Weidmann Deutsche Bundesbank ann.txt\u001b[0m\n",
      "skipping file in language de: 2013-11-21 Merkel Bundesregerung ann g.txt\n",
      "skipping file in language de: 2014-02-27 Merkel Bundesregerung ann g.txt\n",
      "\u001b[31mwarning: mismatch meta data (21) vs file (20) for file 2014-07-18 Weidmann Deutsche Bundesbank ann.txt\u001b[0m\n",
      "skipping file in language de: 2015-01-19 Merkel Bundesregerung ann g.txt\n",
      "skipping file placeholder.txt\n",
      "read 118 files with 897 paragraphs; skipped 16 files\n"
     ]
    }
   ],
   "source": [
    "X, y = make_dataset(speeches, speech_contents, map_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(X,y):\n",
    "    \"\"\"\n",
    "    remove Missing value first, then output two balanced dataset (Undersampling and Oversampling)\n",
    "    Input: X,y before pre-processing\n",
    "    Output: dataframes after removing missing value, Undersampling and Oversampling\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'X':pd.Series(X),'y':pd.Series(y)})\n",
    "    df_true = df[df['y'] == True]\n",
    "    df_false = df[df['y'] == False] \n",
    "    \n",
    "    #Upsampling, for the class with less data, copy some data \n",
    "    df_false_upsampled = resample(df_false,random_state=seed_val,n_samples=len(df_true),replace=True)\n",
    "    df_upsampled = pd.concat([df_false_upsampled,df_true])\n",
    "    df_upsampled = shuffle(df_upsampled)\n",
    "    \n",
    "    #print('\\nWe totally have {} training data after oversampling.'.format(len(df_upsampled)))\n",
    "    return df_upsampled\n",
    "\n",
    "def transform_df(df_upsampled):\n",
    "    #transform label to int\n",
    "    df_upsampled.loc[df_upsampled['y'] == 'True', 'y'] = 1\n",
    "    df_upsampled.loc[df_upsampled['y'] == 'False', 'y'] = 0\n",
    "    df_upsampled.y = df_upsampled.y.astype(int)\n",
    "    \n",
    "    #get sentences and label, will use them to do the tokenization\n",
    "    #sentences = df_upsampled.X.values\n",
    "    #labels = df_upsampled.y.values\n",
    "    return df_upsampled\n",
    "\n",
    "def tokenize_process(df,tokenizer,max_length):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    sentences = df.X.values\n",
    "    labels = df.y.values\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_length,   # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    # Print sentence 0, now as a list of IDs.\n",
    "    #print('Check the original paragraph and converted paragrapg: ')\n",
    "    #print('Original: ', sentences[1])\n",
    "    #print('Token IDs:', input_ids[1])\n",
    "    \n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    return dataset\n",
    "\n",
    "def model_and_helper(train_dataloader,epochs):\n",
    "    #print('\\nLoading bert model.')\n",
    "    # Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "        num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                        # You can increase this for multi-class tasks.   \n",
    "        output_attentions = False, # Whether the model returns attentions weights.\n",
    "        output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        return_dict = False\n",
    "        )\n",
    "    \n",
    "    # Assign GPU if you have\n",
    "    if str(device)=='cuda':\n",
    "        model.cuda()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # set optimizer\n",
    "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "    # the 'W' stands for 'Weight Decay fix\"\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                      eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "                      weight_decay=0.05 # add normalization term\n",
    "                    )\n",
    "    \n",
    "    \n",
    "    # Create the learning rate scheduler and helper functions\n",
    "    epochs = epochs\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    # Create the learning rate scheduler.\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                                num_training_steps = total_steps)\n",
    "    return model,optimizer,scheduler,total_steps\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def Training_and_evaluating(model,train_dataloader,validation_dataloader,optimizer,epochs,scheduler,total_steps,vis_loss):\n",
    "    #print('\\nTraining and evaluating the model.')\n",
    "    \n",
    "    #store a number of quantities such as training and validation loss,validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "    \n",
    "    #store prediction and true labels\n",
    "    train_logits = []\n",
    "    eval_logits = []\n",
    "    train_label = []\n",
    "    eval_label = []\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "        \n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "        \n",
    "        # Perform one full pass over the training set.\n",
    "    \n",
    "            #print(\"\")\n",
    "            #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            #print('Training...')\n",
    "    \n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "    \n",
    "            # Progress update every 40 batches.\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                \n",
    "                # Report progress.\n",
    "                #print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "    \n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].long().to(device)\n",
    "    \n",
    "            model.zero_grad()        \n",
    "            loss, logits = model(b_input_ids, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 labels=b_labels)\n",
    "            \n",
    "            logits_ = logits.detach().cpu().numpy()\n",
    "            label_ids_ = b_labels.to('cpu').numpy()\n",
    "            \n",
    "            #store prediction for the last epoch\n",
    "            if epoch_i == epochs-1:\n",
    "                train_logits.extend(logits_)\n",
    "                train_label.extend(label_ids_)\n",
    "            total_train_loss += loss.item()\n",
    "    \n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "            # Update parameters and take a step using the computed gradient.Update the learning rate.\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "    \n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "    \n",
    "            #print(\"\")\n",
    "            #print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "            #print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "            \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "    \n",
    "            #print(\"\")\n",
    "            #print(\"Running Validation...\")\n",
    "        t0 = time.time()\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "            \n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].long().to(device)\n",
    "            \n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "    \n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       attention_mask=b_input_mask,\n",
    "                                       labels=b_labels)\n",
    "                \n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            if epoch_i == epochs-1:\n",
    "                eval_logits.extend(logits)\n",
    "                eval_label.extend(label_ids)\n",
    "            \n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "            #print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "            #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    \n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        #print(\"\")\n",
    "        #print(\"Training complete!\")\n",
    "        #\n",
    "        #print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    \n",
    "\n",
    "    if vis_loss:\n",
    "        pd.set_option('precision', 2)\n",
    "        # Create a DataFrame from our training statistics.\n",
    "        df_stats = pd.DataFrame(data=training_stats)\n",
    "        # Use the 'epoch' as the row index.\n",
    "        df_stats = df_stats.set_index('epoch')\n",
    "        \n",
    "        # Plot the learning curve.\n",
    "        plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "        plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "        \n",
    "        # Label the plot.\n",
    "        plt.title(\"Training & Validation Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        epoch_list = [i+1 for i in range(10)]\n",
    "        plt.xticks(epoch_list)\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def convert_logits_tolabel(logits):\n",
    "        pred = []\n",
    "        for i in logits:\n",
    "            if i[0]> i[1]:\n",
    "                pred.append(0)\n",
    "            else:\n",
    "                pred.append(1)\n",
    "        return pred\n",
    "    \n",
    "    train_pred = convert_logits_tolabel(train_logits)\n",
    "    eval_pred = convert_logits_tolabel(eval_logits)\n",
    "    \n",
    "    \n",
    "    return model,train_pred,eval_pred,train_label,eval_label\n",
    "\n",
    "def bert_cls(df_train,df_test,epochs = 10,batch_size =16,max_length=128,vis_loss=False):\n",
    "    \n",
    "    #print('\\n======================Doing Bert classification task======================')\n",
    "    \n",
    "    \"\"\"\n",
    "    step1: Tokenization\n",
    "    \"\"\"\n",
    "    #print('Do step1: Tokenization\\n')\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    \n",
    "    train_dataset = tokenize_process(df_train,tokenizer,max_length)\n",
    "    val_dataset = tokenize_process(df_test,tokenizer,max_length)\n",
    "    \n",
    "    \"\"\"\n",
    "    step2: create dataloader for both training and eval set\n",
    "    \"\"\"\n",
    "    #print('\\nDo step3: create dataloader for both training and eval set\\n')\n",
    "    # The DataLoader needs to know our batch size for training, so we specify it \n",
    "    # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "    # size of 16 or 32.\n",
    "    #print('Do step2: create dataloader for both training and eval set\\n')\n",
    "    \n",
    "    batch_size = batch_size\n",
    "    \n",
    "    # Create the DataLoaders for our training and validation sets.\n",
    "    # We'll take training samples in random order. \n",
    "    train_dataloader = DataLoader(train_dataset,sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
    "    \n",
    "    # For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "    validation_dataloader = DataLoader(val_dataset,sampler = SequentialSampler(val_dataset),batch_size = batch_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    step3: load bert model\n",
    "    \"\"\"\n",
    "    #print('Do step3: load bert model\\n')\n",
    "    model,optimizer,scheduler,total_steps = model_and_helper(train_dataloader,epochs)\n",
    "    \n",
    "    \"\"\"\n",
    "    step4: Training and evaluating\n",
    "    \"\"\"\n",
    "    #print('Do step4: Training and evaluating\\n')\n",
    "    model,train_pred,eval_pred,train_label,eval_label = Training_and_evaluating(model,train_dataloader,validation_dataloader,optimizer,epochs,scheduler,total_steps,vis_loss)\n",
    "    \n",
    "    \n",
    "    return model,train_pred,eval_pred,train_label,eval_label #,macro_f1,clas_reprt_train,cm_train,clas_reprt_eval,cm_eval\n",
    "\n",
    "def kfold_bert_exp(df,epochs,vis_loss=False):\n",
    "    \n",
    "    kf = KFold(n_splits=5,random_state=seed_val, shuffle =True)\n",
    "    kf.get_n_splits(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    training_pred = []\n",
    "    training_true = []\n",
    "    evaluation_pred = []\n",
    "    evaluation_true = []\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(df):\n",
    "        \n",
    "        #print('--------------------------------------------------------Now is {} fold--------------------------------------------------------'.format(k))\n",
    "        \n",
    "        X_train, X_test = df['X'][train_index], df['X'][test_index]\n",
    "        y_train, y_test = df['y'][train_index], df['y'][test_index]\n",
    "        \n",
    "        #print('[X training set shape, X test set shape]:',X_train.shape,X_test.shape)\n",
    "        \n",
    "        # over-sample the Training set, then transform them to right form\n",
    "        df_train_upsampled = over_sampling(X_train, y_train)\n",
    "        df_train_upsampled = transform_df(df_train_upsampled)\n",
    "        \n",
    "        # transform testset to right form\n",
    "        df_test = pd.DataFrame({'X':pd.Series(X_test),'y':pd.Series(y_test)})\n",
    "        df_test = transform_df(df_test)\n",
    "        \n",
    "        model,train_pred,eval_pred,train_label,eval_label = bert_cls(df_train_upsampled,df_test,epochs = epochs,batch_size =16,max_length=128,vis_loss=vis_loss)\n",
    "        \n",
    "        training_pred.append(train_pred)\n",
    "        training_true.append(train_label)\n",
    "        evaluation_pred.append(eval_pred)\n",
    "        evaluation_true.append(eval_label)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        k+=1\n",
    "\n",
    "    return evaluation_true,evaluation_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(X,y):\n",
    "    df = pd.DataFrame({'X':pd.Series(X),'y':pd.Series(y)})\n",
    "    print('{} na data found'.format(len(df[df['X'].isna() == True].index)))\n",
    "    df = df.dropna()\n",
    "    print('na data dropped')\n",
    "    \n",
    "    sizes = [100, 300, 500, 700] \n",
    "    macro_f1_list = []\n",
    "    \n",
    "    def flatten(t):\n",
    "        return [item for sublist in t for item in sublist]\n",
    "    \n",
    "    for n_samples in tqdm.tqdm(sizes):\n",
    "        print('\\nNow, the number of samples for the dataset is: {}.'.format(n_samples))\n",
    "        df_resample = resample(df,random_state=seed_val,n_samples=n_samples,replace=True)\n",
    "        evaluation_true,evaluation_pred = kfold_bert_exp(df,epochs = 2,vis_loss=False)\n",
    "        \n",
    "        tmp = []\n",
    "        for i in range(len(evaluation_true)):\n",
    "            macro_f1 = f1_score(evaluation_true[i], evaluation_pred[i], average='macro')\n",
    "            tmp.append(macro_f1)\n",
    "        macro_f1_list.append([tmp])\n",
    "    \n",
    "    print('\\nNow, the number of samples for the dataset is: {}.'.format(df.shape[0]))\n",
    "    evaluation_true,evaluation_pred = kfold_bert_exp(df,epochs = 2,vis_loss=False)\n",
    "    tmp = []\n",
    "    for i in range(len(evaluation_true)):\n",
    "        macro_f1 = f1_score(evaluation_true[i], evaluation_pred[i], average='macro')\n",
    "        tmp.append(macro_f1)\n",
    "    macro_f1_list.append([tmp])\n",
    "    \n",
    "    means = []\n",
    "    stds = []\n",
    "    for i in range(len(macro_f1_list)):\n",
    "        means.append(np.mean(macro_f1_list[i]))\n",
    "        stds.append(np.std(macro_f1_list[i]))\n",
    "    \n",
    "    return means,stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 na data found\n",
      "na data dropped\n",
      "\n",
      "Now, the number of samples for the dataset is: 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 25%|████████████████████▊                                                              | 1/4 [02:46<08:20, 166.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, the number of samples for the dataset is: 300.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [05:33<05:33, 166.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, the number of samples for the dataset is: 500.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [08:21<02:47, 167.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, the number of samples for the dataset is: 700.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [11:08<00:00, 167.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, the number of samples for the dataset is: 878.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "means,stds = sensitivity_analysis(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sensitivity Analysis')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sizes = [100, 300, 500, 700, 878] \n",
    "# define error bar as 2 standard deviations from the mean or 95%\n",
    "err = [min(1, s * 2) for s in stds]\n",
    "# plot dataset size vs mean performance with error bars\n",
    "plt.errorbar(sizes, means, yerr=err, fmt='-o')\n",
    "plt.xlabel('n_samples')\n",
    "plt.ylabel('Macro F1 score')\n",
    "plt.title('Sensitivity Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
